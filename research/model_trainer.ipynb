{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f5f375",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a785e900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8c0026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/satwiksahoo/Desktop/CodeBasics/machine learning/krish naik/NLP project/text_summarizer/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0efb4a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/satwiksahoo/Desktop/CodeBasics/machine learning/krish naik/NLP project/text_summarizer'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "355217db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    root_dir : Path\n",
    "    data_path_train : Path\n",
    "    data_path_test : Path\n",
    "    data_path_validation : Path\n",
    "    model_ckpt : Path\n",
    "    num_train_epochs: int\n",
    "    warmup_steps: int\n",
    "    per_device_train_batch_size: int\n",
    "    weight_decay: float\n",
    "    logging_steps: int\n",
    "    evaluation_strategy: str\n",
    "    eval_steps: int\n",
    "    save_steps: float\n",
    "    gradient_accumulation_steps: int\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0462f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.textSummarizer.constants import *\n",
    "from src.textSummarizer.utils.common import read_yaml , create_directories\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self , config_file_path = CONFIG_FILE_PATH , params_file_path = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root]) \n",
    "    \n",
    "    def get_model_trainer(self) -> ModelTrainerConfig:\n",
    "        \n",
    "        config = self.config.model_trainer\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        \n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "       \n",
    "            \n",
    "            root_dir = config.root_dir,\n",
    "           \n",
    "            data_path_train = config.data_path_train,\n",
    "            data_path_test  = config.data_path_test ,\n",
    "            data_path_validation = config.data_path_validation ,\n",
    "            \n",
    "            model_ckpt = config.model_ckpt,\n",
    "            num_train_epochs = params.num_train_epochs ,\n",
    "            warmup_steps = params.warmup_steps ,\n",
    "            per_device_train_batch_size = params.per_device_train_batch_size ,\n",
    "            weight_decay = params.weight_decay, \n",
    "            logging_steps = params.logging_steps ,\n",
    "            evaluation_strategy = params.evaluation_strategy ,\n",
    "            eval_steps = params.eval_steps ,\n",
    "            save_steps = params.save_steps ,\n",
    "            gradient_accumulation_steps = params.gradient_accumulation_steps\n",
    "            \n",
    "            \n",
    "        )  \n",
    "        \n",
    "        \n",
    "        return model_trainer_config\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c01a0222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from src.textSummarizer.logging import logger\n",
    "import os\n",
    "from datasets import load_from_disk \n",
    "import pandas as pd\n",
    "import re\n",
    "from datasets import Dataset\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self , config : ModelTrainerConfig):\n",
    "        self.config = config \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name) \n",
    "    \n",
    "    \n",
    "    def preprocess_fun(example):\n",
    "        input = tokenizer(example['preprocess_text'] , padding = 'max_length' ,truncation = True , max_length=512)\n",
    "        target = tokenizer(example['summary'] , padding = 'max_length' ,truncation = True , max_length=150)\n",
    "        input['labels'] = target['input_ids']\n",
    "\n",
    "        return input\n",
    "    \n",
    "    def model_training(self):\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.model_ckpt)\n",
    "        model =     AutoModelForSeq2SeqLM.from_pretrained(self.config.model_ckpt)\n",
    "        \n",
    "        dataset = load_from_disk(self.config.data_path)\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "          output_dir='./results',\n",
    "          num_train_epochs=self.params.num_train_epochs,\n",
    "          per_device_train_batch_size=self.params.per_device_train_batch_size,     # smallest batch size\n",
    "          per_device_eval_batch_size=self.params.per_device_eval_batch_size,\n",
    "          weight_decay=self.params.weight_decay,\n",
    "          logging_steps=self.params.logging_steps,\n",
    "          eval_steps=self.params.eval_steps,\n",
    "          save_steps=self.params.save_steps,\n",
    "          gradient_accumulation_steps=self.params.gradient_accumulation_steps,     # no accumulation\n",
    "          eval_strategy=self.params.eval_strategy,\n",
    "          save_total_limit=self.params.save_total_limit,\n",
    "          logging_dir='./logs',\n",
    "    # Uncomment below to force CPU if MPS still crashes\n",
    "    # no_cuda=True,\n",
    "             )\n",
    "        \n",
    "        \n",
    "        \n",
    "        trainer = Trainer(\n",
    "              model=model,\n",
    "              args=training_args,\n",
    "              train_dataset=pd.DataFrame(load_from_disk(self.config.data_path_train)),\n",
    "              eval_dataset=pd.DataFrame(load_from_disk(self.config.data_path_validation))\n",
    "             )\n",
    "        \n",
    "        trainer.train()\n",
    "        \n",
    "        model.save_pretrained(os.path.join(self.config.root_dir , 'bart_model'))\n",
    "        \n",
    "        tokenizer.save_pretrained(os.path.join(self.config.root_dir , 'tokenizer'))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "facf8e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>preprocess_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13820547</td>\n",
       "      <td>Olafur: are we doing anything for New Year's E...</td>\n",
       "      <td>Nathalie, Olafur and Zoe are planning the New ...</td>\n",
       "      <td>olafur: are we doing anything for new year's e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13682134</td>\n",
       "      <td>Javier: Hey do you know any tattoo parlors ove...</td>\n",
       "      <td>Javier was initially eager to have a tatoo don...</td>\n",
       "      <td>javier: hey do you know any tattoo parlors ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13611508</td>\n",
       "      <td>Martha: Hey, can I ask you a question?\\r\\nOphe...</td>\n",
       "      <td>Martha likes Ophelia's lenses and wants to buy...</td>\n",
       "      <td>martha: hey, can i ask you a question? ophelia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13829744</td>\n",
       "      <td>Miranda: Hi S, could we cancel tomorrow's meet...</td>\n",
       "      <td>Miranda can't make her meeting with Stephanie ...</td>\n",
       "      <td>miranda: hi s, could we cancel tomorrow's meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13864860</td>\n",
       "      <td>Sam: Where are you?\\nKate: downstairs\\nSam: al...</td>\n",
       "      <td>Kate and Jeff are downstairs in a room next to...</td>\n",
       "      <td>sam: where are you? kate: downstairs sam: alre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>13681079</td>\n",
       "      <td>Dinny: can you take your dog away before i com...</td>\n",
       "      <td>Dinny's afraid of Terry's dog so he should kee...</td>\n",
       "      <td>dinny: can you take your dog away before i com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>13716791</td>\n",
       "      <td>Lauren: ladies, i'm thinking of getting a tatt...</td>\n",
       "      <td>Lauren want's to have a small tattoo above her...</td>\n",
       "      <td>lauren: ladies, i'm thinking of getting a tatt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>13681192</td>\n",
       "      <td>Crystal: &lt;file_photo&gt;\\r\\nIrene: He's so big!\\r...</td>\n",
       "      <td>Irene will take Crystal's son shopping for clo...</td>\n",
       "      <td>crystal:   irene: he's so big! crystal:   crys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>13682321</td>\n",
       "      <td>Kate: I've just heard you want to sell your fl...</td>\n",
       "      <td>Rob wants to sell his flat, because it's too s...</td>\n",
       "      <td>kate: i've just heard you want to sell your fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>13829218</td>\n",
       "      <td>Adam: Did you take the dog for a walk?\\r\\nMike...</td>\n",
       "      <td>Mike didn't have time to take the dog for a wa...</td>\n",
       "      <td>adam: did you take the dog for a walk? mike: n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           dialogue  \\\n",
       "0    13820547  Olafur: are we doing anything for New Year's E...   \n",
       "1    13682134  Javier: Hey do you know any tattoo parlors ove...   \n",
       "2    13611508  Martha: Hey, can I ask you a question?\\r\\nOphe...   \n",
       "3    13829744  Miranda: Hi S, could we cancel tomorrow's meet...   \n",
       "4    13864860  Sam: Where are you?\\nKate: downstairs\\nSam: al...   \n",
       "..        ...                                                ...   \n",
       "595  13681079  Dinny: can you take your dog away before i com...   \n",
       "596  13716791  Lauren: ladies, i'm thinking of getting a tatt...   \n",
       "597  13681192  Crystal: <file_photo>\\r\\nIrene: He's so big!\\r...   \n",
       "598  13682321  Kate: I've just heard you want to sell your fl...   \n",
       "599  13829218  Adam: Did you take the dog for a walk?\\r\\nMike...   \n",
       "\n",
       "                                               summary  \\\n",
       "0    Nathalie, Olafur and Zoe are planning the New ...   \n",
       "1    Javier was initially eager to have a tatoo don...   \n",
       "2    Martha likes Ophelia's lenses and wants to buy...   \n",
       "3    Miranda can't make her meeting with Stephanie ...   \n",
       "4    Kate and Jeff are downstairs in a room next to...   \n",
       "..                                                 ...   \n",
       "595  Dinny's afraid of Terry's dog so he should kee...   \n",
       "596  Lauren want's to have a small tattoo above her...   \n",
       "597  Irene will take Crystal's son shopping for clo...   \n",
       "598  Rob wants to sell his flat, because it's too s...   \n",
       "599  Mike didn't have time to take the dog for a wa...   \n",
       "\n",
       "                                       preprocess_text  \n",
       "0    olafur: are we doing anything for new year's e...  \n",
       "1    javier: hey do you know any tattoo parlors ove...  \n",
       "2    martha: hey, can i ask you a question? ophelia...  \n",
       "3    miranda: hi s, could we cancel tomorrow's meet...  \n",
       "4    sam: where are you? kate: downstairs sam: alre...  \n",
       "..                                                 ...  \n",
       "595  dinny: can you take your dog away before i com...  \n",
       "596  lauren: ladies, i'm thinking of getting a tatt...  \n",
       "597  crystal:   irene: he's so big! crystal:   crys...  \n",
       "598  kate: i've just heard you want to sell your fl...  \n",
       "599  adam: did you take the dog for a walk? mike: n...  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk \n",
    "import pandas as pd\n",
    "dataset = load_from_disk('artifacts/data_transformation/test_dataset')\n",
    "pd.DataFrame(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e844c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'dialogue', 'summary', 'preprocess_text'],\n",
       "    num_rows: 600\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigurationManager()\n",
    "model_trainer_config = config.get_model_trainer()\n",
    "model_trainer = ModelTrainer(config = model_trainer_config)\n",
    "model_trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
